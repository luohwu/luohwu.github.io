
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/html">

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>IBM Call for Code Challenge</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <meta property="og:image" content="https://jonbarron.info/mipnerf360/img/gardenvase.jpg">
    <meta property="og:image:type" content="image/png">
    <meta property="og:image:width" content="1296">
    <meta property="og:image:height" content="840">
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://jonbarron.info/mipnerf360/"/>
    <meta property="og:title" content="Mip-NeRF 360: Unbounded Anti-Aliased Neural Radiance Fields" />
    <meta property="og:description" content="Though neural radiance fields (NeRF) have demonstrated impressive view synthesis results on objects and small bounded regions of space, they struggle on 'unbounded' scenes, where the camera may point in any direction and content may exist at any distance. In this setting, existing NeRF-like models often produce blurry or low-resolution renderings (due to the unbalanced detail and scale of nearby and distant objects), are slow to train, and may exhibit artifacts due to the inherent ambiguity of the task of reconstructing a large scene from a small set of images. We present an extension of mip-NeRF (a NeRF variant that addresses sampling and aliasing) that uses a non-linear scene parameterization, online distillation, and a novel distortion-based regularizer to overcome the challenges presented by unbounded scenes. Our model, which we dub 'mip-NeRF 360' as we target scenes in which the camera rotates 360 degrees around a point, reduces mean-squared error by 54% compared to mip-NeRF, and is able to produce realistic synthesized views and detailed depth maps for highly intricate, unbounded real-world scenes." />

    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="Mip-NeRF 360: Unbounded Anti-Aliased Neural Radiance Fields" />
    <meta name="twitter:description" content="Though neural radiance fields (NeRF) have demonstrated impressive view synthesis results on objects and small bounded regions of space, they struggle on 'unbounded' scenes, where the camera may point in any direction and content may exist at any distance. In this setting, existing NeRF-like models often produce blurry or low-resolution renderings (due to the unbalanced detail and scale of nearby and distant objects), are slow to train, and may exhibit artifacts due to the inherent ambiguity of the task of reconstructing a large scene from a small set of images. We present an extension of mip-NeRF (a NeRF variant that addresses sampling and aliasing) that uses a non-linear scene parameterization, online distillation, and a novel distortion-based regularizer to overcome the challenges presented by unbounded scenes. Our model, which we dub 'mip-NeRF 360' as we target scenes in which the camera rotates 360 degrees around a point, reduces mean-squared error by 54% compared to mip-NeRF, and is able to produce realistic synthesized views and detailed depth maps for highly intricate, unbounded real-world scenes." />
    <meta name="twitter:image" content="https://jonbarron.info/mipnerf360/img/gardenvase.jpg" />


<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>💫</text></svg>">

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">

    <link rel="stylesheet" href="css/bootstrap.min.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    
    <script src="js/app.js"></script>
</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h2 class="col-md-12 text-center">
                <b>Climate change and Infectious Disease</b>
<!--                <b>Mip-NeRF 360</b>: Unbounded <br> Anti-Aliased Neural Radiance Fields</br> -->
<!--                <small>-->
<!--								CVPR 2022 (Oral Presentation)-->
<!--                </small>-->
            </h2>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        <a href="https://luohwu.github.io">
                          Luohong Wu
                        </a>
                        </br>ETHZ
                    </li>
                    <li>
                          Chenyu Shen
                        </br>ETHZ
                    </li>
                    <li>
                          Wynne Katherine
                        </br>University of Tokyo
                    </li>

                </ul>
            </div>
        </div>


        <div class="row">
                <div class="col-md-4 col-md-offset-4 text-center">
                    <ul class="nav nav-pills nav-justified">
<!--                        <li>-->
<!--                            <a href="https://luohwu.github.io/Faster SURF/paper/MAKING_SPEEDED_UP_ROBUST_FEATURES__SURF__FASTER.pdf">-->
<!--                                <image src="img/paper_image.jpg" height="60px"></image>>-->
<!--                                <h4><strong>Paper</strong></h4>-->
<!--                            </a>-->
<!--                        </li>-->
<!--                        <li>-->
<!--                            <a href="https://youtu.be/zBSH-k9GbV4">-->
<!--                            <image src="img/youtube_icon.png" height="60px">-->
<!--                                <h4><strong>Video</strong></h4>-->
<!--                            </a>-->
<!--                        </li>-->
<!--                        <li>-->
<!--                            <a href="http://storage.googleapis.com/gresearch/refraw360/360_v2.zip">-->
<!--                            <image src="img/database_icon.png" height="60px">-->
<!--                                <h4><strong>Dataset</strong></h4>-->
<!--                            </a>-->
<!--                        </li>-->
                        <!-- <li>
                            <a href="TODO">
                            <image src="img/github.png" height="60px">
                                <h4><strong>Code</strong></h4>
                            </a>
                        </li> -->
                    </ul>
                </div>
        </div>



<!--        <div class="row">-->
<!--            <div class="col-md-8 col-md-offset-2">-->
<!--                <video id="v0" width="100%" autoplay loop muted controls>-->
<!--                  <source src="img/gardenvase_720.mp4" type="video/mp4" />-->
<!--                </video>-->
<!--						</div>-->
<!--            <div class="col-md-8 col-md-offset-2">-->
<!--							<p class="text-center">-->
<!--							Rendered images and depths from our model.-->
<!--							</p>-->
<!--						</div>-->
<!--        </div>-->
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Background
                </h3>
                This is a team project in the 2-weeks <a href="https://ethz.ch/students/en/news/student-news/2021/07/ibm-call-for-code-research-challenge.html">
                2021 IBM Call for Code Research Challenge for Climate Change</a>. Provided the powerful platforms and rich datasets from IBM, we attack the challenge theme: Climate Change.
                <br>
                <div>
                    <image src="img/certificate.jpeg" width="800"></image>
                </div>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Video
                </h3>
                If your browser doesn't support this embedded video, please check <a href="https://video.ibm.com/recorded/130982861"> here</a> The introduction
                of our project starts at around 33:57.
                <div class="text-center">
                    <div style="position:relative;padding-top:56.25%;">
                        <iframe src="https://video.ibm.com/embed/recorded/130982861" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
                    </div>
                </div>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Description
                </h3>
                <p class="text-justify">
                    Thanks to the improvement of sanitary and hygiene, the worldwide burden of infectious disease has fallen over the past few decades. However, the covid-19 pandemic just shows us how great the threat to global health remains – especially as the climate crisis continues to affect the transmission of disease in a variety of ways. At the moment, changing environment is demolishing our planet’s defence system people used to rely on. One way in which climate change will affect the risk of diseases spreading is by making new areas into suitable homes for disease-carrying species. For example, rising temperatures and precipitation are making temperate, mountainous countries more susceptible to outbreaks of "tropical" or “low land” diseases like malaria. The arrival and rapid spread of the mosquito-borne viral disease across the world is one of the most significant challenge for public health developments of recent years. In order to prepare for future outbreaks, it is necessary to anticipate global regions that could become suitable for disease transmission.
                </p>

                <p class="text-justify">
                    In our project, by using the climate data from IBM PAIRS and The Weather Company, and surveillance of Anophelines’ occurrence from Malarial Mosquito Database , we aim to study the relationship between climate condition and survivability of disease vectors like Anophelines. More specifically, given a location’s climate conditions like temperature and precipitation, we trained a neural network (Fig 1.) to predict how possible Anophelines can survive in terms of climate condition. Due to time constraint, we trained our network using only data of Anopheline Funestus in the Sub-Saharan Africa, and the input features are monthly minimum temperatures and monthly maximum temperatures. And we applied our model to climate forecast during 2021-2040, the result is depicted by Fig 2. According to the result, due to effect of climate change, the climate condition of Portugal and Spain in the coming future is suitable for Anopheline to spread. And since there are travel between Sub-Saharan Africa and Portugal and Spain, the two countries will be in the risk of disease transmission.
                </p>

            </div>
        </div>




        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                    Figure 1. Our simple model
                <div>
                    <image src="img/figure 1.png" width="800"></image>
                </div>
<!--                <div class="text-center">-->

<!--                    <div style="position:relative;padding-top:66.25%;" >-->

<!--                        <image src="img/figure 1.png" style="position:absolute;top:0;left:0;width:100%;height:70%;"></image>-->
<!--                    </div>-->
<!--                </div>-->
            </div>
            <div class="col-md-8 col-md-offset-2">
            <p><br></p>
            </div>
            <div class="col-md-8 col-md-offset-2">
                    Figure 2. Prediction result using data of 2022~2040
                <div>
                    <image src="img/figure 2.png" width="800"></image>
                </div>
<!--                <div class="text-center">-->

<!--                    <div style="position:relative;padding-top:66.25%;">-->
<!--                        <image src="img/figure 2.png" style="position:absolute;top:0;left:0;width:100%;height:110%;"></image>-->
<!--                    </div>-->
<!--                </div>-->
            </div>

        </div>



<!--        <div class="row">-->
<!--            <div class="col-md-8 col-md-offset-2">-->
<!--                <h3>-->
<!--                    Simulation of the old slow Model Predictive Controller-->
<!--                </h3>-->
<!--                <div class="text-center">-->
<!--                    <div style="position:relative;padding-top:56.25%;">-->
<!--                        <iframe src="https://youtube.com/embed/P4xwSANzpwk" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>-->
<!--                    </div>-->
<!--                </div>-->
<!--            </div>-->
<!--        </div>-->

            


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Acknowledgements
                </h3>
                <p class="text-justify">
                The website template was borrowed from <a href="http://mgharbi.com/">Michaël Gharbi</a>.
                </p>
            </div>
        </div>

    </div>
</body>
</html>
